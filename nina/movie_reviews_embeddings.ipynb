{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_reviews_embeddings.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "15IJhjOCTSEWuR1H0VF1z8krxcduHAMN1",
      "authorship_tag": "ABX9TyOB1xsP81vWFpO0Q0FLhd7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skanderbenmansour/nlp_study_group/blob/master/nina/movie_reviews_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcz8qOd_COVL",
        "colab_type": "code",
        "outputId": "87130bd9-be8d-44c1-c77a-f6953220d2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/21/4936b881b33de285faa0b36209afe4f9724a0875b2225abdc63b23d384a3/skorch-0.8.0-py3-none-any.whl (113kB)\n",
            "\r\u001b[K     |██▉                             | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.38.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.18.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.14.1)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3UxPwdeIQ4Q",
        "colab_type": "code",
        "outputId": "7810198c-0d86-48f0-e21c-4712f59f3310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import re\n",
        "from random import shuffle\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f19236d2bf0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO0srbM-CP2X",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgpUwUKyIcus",
        "colab_type": "text"
      },
      "source": [
        "## Load and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkCKml_ZIbL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_pos = '/content/drive/My Drive/Datasets/review_polarity/txt_sentoken/pos'\n",
        "path_neg = '/content/drive/My Drive/Datasets/review_polarity/txt_sentoken/neg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20WjShvZIluq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(doc):\n",
        "    return [re.sub('[^\\w]|[\\d]','', word.lower()) for word in doc]\n",
        "\n",
        "def remove_words(vocab):\n",
        "    return [i for i in vocab if i not in ['', 'a','it','the', 'i']]\n",
        "\n",
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def make_ngram_vector(sentence, word_to_ix, n=3):\n",
        "    ngram_vectors = []\n",
        "    for i in range(len(sentence) - n):\n",
        "        curr_ngram = [[], None]     \n",
        "        for j in range(n):\n",
        "            if j == n-1:\n",
        "                curr_ngram[1] = sentence[i + j]\n",
        "            else:\n",
        "                curr_ngram[0].append(sentence[i + j])\n",
        "        ngram_vectors.append(curr_ngram)\n",
        "\n",
        "    return ngram_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eammd1ECJII8",
        "colab_type": "code",
        "outputId": "2bf7d1bb-5956-4e71-afc7-b11136a0815a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "data = []\n",
        "\n",
        "# load data in\n",
        "for path in glob.glob(path_pos+'/*.txt'):\n",
        "  with open(path, 'r') as f:\n",
        "    data.append((preprocess(f.read().replace('\\n', ' ').split()), \"P\"))\n",
        "\n",
        "print('finished positive reviews')\n",
        "\n",
        "for path in glob.glob(path_neg+'/*.txt'):\n",
        "  with open(path, 'r') as f:\n",
        "    data.append((preprocess(f.read().replace('\\n', ' ').split()), \"N\"))\n",
        "\n",
        "print('finished negative reviews')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished positive reviews\n",
            "finished negative reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfT-JOGJJLsW",
        "colab_type": "text"
      },
      "source": [
        "## Transform sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeF_SKvEMx74",
        "colab_type": "code",
        "outputId": "2a7fd18d-255e-44d5-b4fe-60fb4a60cb23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[0][0][1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'am'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbTVW_WOe8Le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data_text = np.array([np.array(text)[:50] for text, label in data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQVzoi0biN0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_text = np.concatenate(data_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMTkaGbuMqah",
        "colab_type": "code",
        "outputId": "78eaea87-0dcc-42a3-c126-d559512457ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(\"hello there\".split())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hello', 'there'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLDKBiDX_AUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set(remove_words(data_text))\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# triples\n",
        "ngram = []\n",
        "X_ngram = []\n",
        "\n",
        "ngram = make_ngram_vector(remove_words(data_text), word_to_ix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xuQsERBkk4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [make_context_vector(i, word_to_ix) for i,j in ngram]\n",
        "y = [torch.tensor([word_to_ix[j]], dtype=torch.long) for i,j in ngram ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjtMO177QGor",
        "colab_type": "code",
        "outputId": "4cc1a18d-85c3-4469-a501-9fe30ebad2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X[1], y[1]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5478, 5480]), tensor([1498]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atxjUEETuOSi",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUCglXGL-zMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 10\n",
        "VOCAB_SIZE = len(vocab)\n",
        "\n",
        "\n",
        "class NGramLanguageModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(NGramLanguageModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # print(inputs.shape)\n",
        "        embeds = self.embeddings(inputs).view((-1, 20))\n",
        "        out = self.linear1(embeds)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        log_probs = F.softmax(out, dim=1)\n",
        "        return log_probs\n",
        "\n",
        "\n",
        "net_ngram = NeuralNetClassifier(\n",
        "    NGramLanguageModeler(VOCAB_SIZE, EMBEDDING_DIM, CONTEXT_SIZE),\n",
        "    max_epochs=20,\n",
        "    lr=0.1,\n",
        "    optimizer=optim.SGD,\n",
        "    optimizer__lr=0.01,\n",
        "    #train_split=None,\n",
        "    # Shuffle training data on each epoch\n",
        "    iterator_train__shuffle=False,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qffo0aR5Rt3h",
        "colab_type": "code",
        "outputId": "1756f16a-ff98-4b0a-efe4-f760394a8017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.stack(X).squeeze().shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([76806, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2PZOXBtQTmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(torch.stack(X).squeeze(), torch.stack(y).squeeze(), test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgXpVEd0Rina",
        "colab_type": "code",
        "outputId": "52e21496-5dca-418d-b48e-ca2786884c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# X_train.shape, y_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([57604, 2]), torch.Size([57604]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWoB36AuTOu",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTuJ2ecAcF1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_e = torch.stack(X).squeeze()\n",
        "y_e = torch.stack(y).squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnFPy_v0eF8y",
        "colab_type": "code",
        "outputId": "cddd253e-1c09-49dc-e5d4-0df51f9a145d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_e.shape, y_e.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([76806, 2]), torch.Size([76806]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF-1RxYQQPWS",
        "colab_type": "code",
        "outputId": "5bf7363a-d3cf-4091-def8-2741fa314f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "net_ngram.fit(X_e, y_e)  "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m9.3681\u001b[0m       \u001b[32m0.0318\u001b[0m        \u001b[35m9.2758\u001b[0m  26.2587\n",
            "      2        \u001b[36m9.1761\u001b[0m       \u001b[32m0.0329\u001b[0m        \u001b[35m9.0737\u001b[0m  32.1723\n",
            "      3        \u001b[36m8.9557\u001b[0m       0.0329        \u001b[35m8.8415\u001b[0m  31.9417\n",
            "      4        \u001b[36m8.7282\u001b[0m       0.0324        \u001b[35m8.6360\u001b[0m  31.6852\n",
            "      5        \u001b[36m8.5474\u001b[0m       0.0316        \u001b[35m8.4833\u001b[0m  31.5739\n",
            "      6        \u001b[36m8.4090\u001b[0m       0.0324        \u001b[35m8.3587\u001b[0m  31.5368\n",
            "      7        \u001b[36m8.2891\u001b[0m       0.0329        \u001b[35m8.2466\u001b[0m  31.5278\n",
            "      8        \u001b[36m8.1824\u001b[0m       \u001b[32m0.0338\u001b[0m        \u001b[35m8.1500\u001b[0m  31.7271\n",
            "      9        \u001b[36m8.0929\u001b[0m       0.0332        \u001b[35m8.0713\u001b[0m  31.5961\n",
            "     10        \u001b[36m8.0199\u001b[0m       \u001b[32m0.0346\u001b[0m        \u001b[35m8.0074\u001b[0m  31.8888\n",
            "     11        \u001b[36m7.9594\u001b[0m       \u001b[32m0.0356\u001b[0m        \u001b[35m7.9542\u001b[0m  31.8606\n",
            "     12        \u001b[36m7.9077\u001b[0m       0.0356        \u001b[35m7.9083\u001b[0m  31.9794\n",
            "     13        \u001b[36m7.8621\u001b[0m       \u001b[32m0.0360\u001b[0m        \u001b[35m7.8679\u001b[0m  36.3240\n",
            "     14        \u001b[36m7.8212\u001b[0m       \u001b[32m0.0361\u001b[0m        \u001b[35m7.8320\u001b[0m  32.7184\n",
            "     15        \u001b[36m7.7845\u001b[0m       \u001b[32m0.0365\u001b[0m        \u001b[35m7.8000\u001b[0m  31.7844\n",
            "     16        \u001b[36m7.7515\u001b[0m       0.0365        \u001b[35m7.7716\u001b[0m  31.4525\n",
            "     17        \u001b[36m7.7218\u001b[0m       \u001b[32m0.0365\u001b[0m        \u001b[35m7.7464\u001b[0m  31.4632\n",
            "     18        \u001b[36m7.6950\u001b[0m       \u001b[32m0.0366\u001b[0m        \u001b[35m7.7238\u001b[0m  31.8031\n",
            "     19        \u001b[36m7.6706\u001b[0m       \u001b[32m0.0367\u001b[0m        \u001b[35m7.7035\u001b[0m  31.8461\n",
            "     20        \u001b[36m7.6482\u001b[0m       0.0365        \u001b[35m7.6850\u001b[0m  31.7552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=NGramLanguageModeler(\n",
              "    (embeddings): Embedding(12359, 10)\n",
              "    (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
              "    (linear2): Linear(in_features=128, out_features=12359, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}