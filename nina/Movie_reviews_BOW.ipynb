{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_reviews_BOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1qVNOlUbLSdo6DrMagBQEXmmDXOdhaMo9",
      "authorship_tag": "ABX9TyODNIOfkS/A5rR/jFDbxJGM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcOzyP5jGHFj",
        "colab_type": "code",
        "outputId": "47323acd-9868-4bd7-b165-5841096bc85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/21/4936b881b33de285faa0b36209afe4f9724a0875b2225abdc63b23d384a3/skorch-0.8.0-py3-none-any.whl (113kB)\n",
            "\r\u001b[K     |██▉                             | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 92kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.18.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.38.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.14.1)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Z2JUIbp_WY",
        "colab_type": "code",
        "outputId": "e72d120b-83dd-489f-b1a4-ddd76954daa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import re\n",
        "from random import shuffle\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc6a313a090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X3gZdqj-Fbv",
        "colab_type": "text"
      },
      "source": [
        "# Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1O1g1F2FSFF",
        "colab_type": "text"
      },
      "source": [
        "## Load and preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_usMytt0RDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_pos = '/content/drive/My Drive/Datasets/review_polarity/txt_sentoken/pos'\n",
        "path_neg = '/content/drive/My Drive/Datasets/review_polarity/txt_sentoken/neg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsn5d8PjdShG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(doc):\n",
        "    return [re.sub('[^\\w]|[\\d]','', word.lower()) for word in doc]\n",
        "\n",
        "def generate_word_mapping(data):\n",
        "    # word_to_ix maps each word in the vocab to a unique integer, which will be its\n",
        "    # index into the Bag of words vector\n",
        "    word_to_ix = {}\n",
        "    for sent, _ in data:\n",
        "        for word in sent:\n",
        "            if word not in word_to_ix:\n",
        "                word_to_ix[word] = len(word_to_ix)\n",
        "    return word_to_ix\n",
        "\n",
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        vec[word_to_ix[word]] += 1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def make_ngram_vector(sentence, word_to_ix, n=3):\n",
        "    ngram_vectors = []\n",
        "    for i in range(len(sentence) - n):\n",
        "        curr_ngram = []      \n",
        "        for j in range(n):\n",
        "            curr_ngram.append(sentence[i + j])\n",
        "\n",
        "        ngram_vectors.append(make_context_vector(curr_ngram, word_to_ix))\n",
        "\n",
        "    return torch.stack(ngram_vectors)\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    return torch.LongTensor([label_to_ix[label]])\n",
        "\n",
        "def get_probs(sm, output):\n",
        "    probabilities = sm(output) \n",
        "    return probabilities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UThSUhiSmg0M",
        "colab_type": "code",
        "outputId": "a2047b9b-d745-4dda-8f79-c6d97a9b3072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preprocess(['hello','there!','Why.','are','you**!2','here'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'there', 'why', 'are', 'you', 'here']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8RYyqC-1M-G",
        "colab_type": "code",
        "outputId": "f14f7b18-8ef9-4653-a1b8-04223ddd67cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "data = []\n",
        "\n",
        "# load data in\n",
        "for path in glob.glob(path_pos+'/*.txt'):\n",
        "  with open(path, 'r') as f:\n",
        "    data.append((preprocess(f.read().replace('\\n', ' ').split()), \"P\"))\n",
        "\n",
        "print('finished positive reviews')\n",
        "\n",
        "for path in glob.glob(path_neg+'/*.txt'):\n",
        "  with open(path, 'r') as f:\n",
        "    data.append((preprocess(f.read().replace('\\n', ' ').split()), \"N\"))\n",
        "\n",
        "print('finished negative reviews')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished positive reviews\n",
            "finished negative reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LePyE2x-OmJ",
        "colab_type": "text"
      },
      "source": [
        "## Transform sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs83hSpyNofx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_ix = {\"N\": 0, \"P\": 1}\n",
        "word_to_ix = generate_word_mapping(data)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for instance, label in data:\n",
        "    words = [i for i in instance if i not in ['', 'a','it','the']][:200]\n",
        "    X.append(make_bow_vector(words, word_to_ix))\n",
        "    y.append(make_target(label, label_to_ix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Tze1xdj2Lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "233bb555-575d-42a9-cd0f-9416a8fe0443"
      },
      "source": [
        "[i for i in data[0][0] if i not in ['', 'a','it', 'the']][:2]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo_Bkl-qU6Wy",
        "colab_type": "code",
        "outputId": "8753d9da-3832-48f0-e06d-6da6d0d176c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "(data[0][1], data[1][1]), X[:2], y[:2]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('P', 'P'),\n",
              " [tensor([[6., 1., 1.,  ..., 0., 0., 0.]]),\n",
              "  tensor([[2., 1., 0.,  ..., 0., 0., 0.]])],\n",
              " [tensor([1]), tensor([1])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruIKVAgCHg9n",
        "colab_type": "text"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9riN5W80MUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_LABELS = 2\n",
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 10\n",
        "\n",
        "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
        "\n",
        "    def __init__(self, num_labels, vocab_size):\n",
        "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
        "        # just always do it in an nn.Module\n",
        "        super(BoWClassifier, self).__init__()\n",
        "\n",
        "        # Define the parameters that you will need.  In this case, we need A and b,\n",
        "        # the parameters of the affine mapping.\n",
        "        # Torch defines nn.Linear(), which provides the affine map.\n",
        "        # Make sure you understand why the input dimension is vocab_size\n",
        "        # and the output is num_labels!\n",
        "        self.linear = nn.Linear(vocab_size, num_labels)\n",
        "\n",
        "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
        "        # to worry about that here\n",
        "\n",
        "    def forward(self, bow_vec):\n",
        "        # Pass the input through the linear layer,\n",
        "        # then pass that through log_softmax.\n",
        "        # Many non-linearities and other functions are in torch.nn.functional\n",
        "        return F.softmax(self.linear(bow_vec), dim=1)\n",
        "\n",
        "\n",
        "\n",
        "net_bag = NeuralNetClassifier(\n",
        "    BoWClassifier(NUM_LABELS, VOCAB_SIZE),\n",
        "    criterion=torch.nn.NLLLoss,\n",
        "    max_epochs=20,\n",
        "    lr=0.00025,\n",
        "    optimizer=optim.SGD,\n",
        "    optimizer__lr=0.1,\n",
        "    # Shuffle training data on each epoch\n",
        "    iterator_train__shuffle=False,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCpunQRYPYbm",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtpR6d1V2ID7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh3fUfBHf1YU",
        "colab_type": "code",
        "outputId": "e61dac5f-da08-4a67-bd31-86420bc09ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.stack(X).shape\n",
        "torch.stack(X).squeeze().shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2000, 47038])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77hg7MWTPbMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(torch.stack(X).squeeze(), torch.stack(y).squeeze(), test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVV8AucQXEGB",
        "colab_type": "code",
        "outputId": "e018461b-94c7-49bd-ef86-bdc27671ae3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train, y_test[:10]"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 1, ..., 1, 0, 0]), array([0, 1, 0, 1, 0, 0, 1, 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyQdNqh4QyTx",
        "colab_type": "code",
        "outputId": "b0883fc7-b2f9-4564-d29f-8231cf301a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "net_bag.fit(X_train, y_train)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.6371\u001b[0m       \u001b[32m0.5067\u001b[0m        \u001b[35m5.8536\u001b[0m  0.2304\n",
            "      2        4.6363       0.5067        \u001b[35m3.3638\u001b[0m  0.2280\n",
            "      3        \u001b[36m3.0277\u001b[0m       0.4933        5.2702  0.2146\n",
            "      4        3.4089       0.4967        4.1637  0.2140\n",
            "      5        3.3032       0.5000        3.7861  0.2161\n",
            "      6        \u001b[36m2.8683\u001b[0m       \u001b[32m0.5433\u001b[0m        \u001b[35m2.7286\u001b[0m  0.2089\n",
            "      7        \u001b[36m2.5024\u001b[0m       \u001b[32m0.5800\u001b[0m        \u001b[35m2.0790\u001b[0m  0.2164\n",
            "      8        \u001b[36m2.1876\u001b[0m       \u001b[32m0.5967\u001b[0m        \u001b[35m1.7096\u001b[0m  0.2121\n",
            "      9        \u001b[36m1.8969\u001b[0m       \u001b[32m0.6100\u001b[0m        \u001b[35m1.5508\u001b[0m  0.2088\n",
            "     10        \u001b[36m1.6466\u001b[0m       \u001b[32m0.6167\u001b[0m        \u001b[35m1.3984\u001b[0m  0.2160\n",
            "     11        \u001b[36m0.9415\u001b[0m       0.5167        3.0954  0.2118\n",
            "     12        3.3791       0.5267        3.0802  0.2122\n",
            "     13        3.0703       0.5433        2.8052  0.2096\n",
            "     14        2.7474       0.5667        2.3157  0.2089\n",
            "     15        2.4638       0.5767        1.9530  0.2203\n",
            "     16        2.2277       0.6067        1.6846  0.2121\n",
            "     17        2.0023       \u001b[32m0.6367\u001b[0m        1.4756  0.2135\n",
            "     18        1.7004       \u001b[32m0.6433\u001b[0m        \u001b[35m1.2663\u001b[0m  0.2082\n",
            "     19        1.2320       \u001b[32m0.6733\u001b[0m        \u001b[35m1.1473\u001b[0m  0.2134\n",
            "     20        \u001b[36m0.6299\u001b[0m       \u001b[32m0.6867\u001b[0m        \u001b[35m0.9489\u001b[0m  0.2117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=BoWClassifier(\n",
              "    (linear): Linear(in_features=47038, out_features=2, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSjf9Bf1Q_sw",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_XvkIZDRC-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDYbMH5yRIP-",
        "colab_type": "code",
        "outputId": "8927d516-f0cc-4373-badc-2d8621260a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = net_bag.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.644"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luex7f4kgeYS",
        "colab_type": "code",
        "outputId": "a184b56f-b0a2-4a8a-a14c-debd41aa3351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[161,  82],\n",
              "       [ 96, 161]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    }
  ]
}