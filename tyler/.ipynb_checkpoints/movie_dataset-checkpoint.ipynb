{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "source is https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/tyler/Documents/programming/pytorch_nlp/data/word2vec-nlp-tutorial/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+'labeledTrainData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[:7500]\n",
    "train = df[7500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'asdf', 'asdfsd', '.', '$', '5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('d asdf asdfsd. $5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    tokens = word_tokenize(review)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    tokens = [t.replace('/','') for t in tokens]\n",
    "    tokens = [t.replace('\\\\','') for t in tokens]\n",
    "    tokens = [t.replace('>','') for t in tokens]\n",
    "    tokens = [t.replace('<','') for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make vocab and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e024bd7ea1a043528cbdcdfa5cfdd650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = list(train.sentiment)\n",
    "reviews = list(train.review.values)\n",
    "\n",
    "all_words = [process_review(review) for review in tqdm(reviews)]\n",
    "\n",
    "train_data = list(zip(all_words,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in all_words for item in sublist]\n",
    "vocab = set(flat_list)\n",
    "\n",
    "len(vocab)\n",
    "\n",
    "word_to_idx = {word:idx for idx,word in enumerate(list(vocab))}\n",
    "\n",
    "counts = Counter(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word = {idx:word for word,idx in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049bd4cadc3a4281a761ebe73a63edf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = list(test.sentiment)\n",
    "reviews = list(test.review.values)\n",
    "\n",
    "all_words = [process_review(review) for review in tqdm(reviews)]\n",
    "\n",
    "test_data = list(zip(all_words,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_to_idx)\n",
    "NUM_LABELS = 2\n",
    "\n",
    "\n",
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "\n",
    "def make_bow_vector(sentence, word_to_idx):\n",
    "    vec = torch.zeros(len(word_to_idx))\n",
    "    for word in sentence:\n",
    "        if word in word_to_idx:\n",
    "            vec[word_to_idx[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = make_bow_vector('this is aasd fast d sentence'.split(),word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ix = {'negative': 0, 'positive': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6948, -0.6915]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sample = all_words[0]\n",
    "    bow_vector = make_bow_vector(sample[0], word_to_idx)\n",
    "    log_probs = model(bow_vector)\n",
    "    print(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: loss of 860449.916\n",
      "Epoch 2/5: loss of 612736.484\n",
      "Epoch 3/5: loss of 491620.345\n",
      "Epoch 4/5: loss of 440858.004\n",
      "Epoch 5/5: loss of 375019.431\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for sentence, label in train_data:\n",
    "        model.zero_grad()\n",
    "\n",
    "        vec = make_bow_vector(sentence, word_to_idx)\n",
    "        target = torch.LongTensor([label])\n",
    "\n",
    "        log_probs = model(vec)\n",
    "\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}: loss of {round(total_loss,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss of 162082.578\n",
      "Train accuracy of 89.65\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "num_correct = 0\n",
    "to_eval = train_data\n",
    "for sentence, label in to_eval:\n",
    "    model.eval()\n",
    "\n",
    "    vec = make_bow_vector(sentence, word_to_idx)\n",
    "    target = torch.LongTensor([label])\n",
    "\n",
    "    log_probs = model(vec)\n",
    "    pred = log_probs.argmax().detach().numpy()\n",
    "    correct = int(pred == label)\n",
    "    num_correct += correct\n",
    "    loss = loss_function(log_probs, target)\n",
    "\n",
    "    total_loss += loss.item()\n",
    "print(f'Train loss of {round(total_loss,3)}')\n",
    "print(f'Train accuracy of {round(num_correct*100/len(to_eval),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss of 125092.704\n",
      "Test accuracy of 86.01\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "total_loss = 0\n",
    "num_correct = 0\n",
    "to_eval = test_data\n",
    "for sentence, label in to_eval:\n",
    "    model.eval()\n",
    "\n",
    "    vec = make_bow_vector(sentence, word_to_idx)\n",
    "    target = torch.LongTensor([label])\n",
    "\n",
    "    log_probs = model(vec)\n",
    "    pred = log_probs.argmax().detach().numpy()\n",
    "    correct = int(pred == label)\n",
    "    num_correct += correct\n",
    "    loss = loss_function(log_probs, target)\n",
    "\n",
    "    total_loss += loss.item()\n",
    "print(f'Test loss of {round(total_loss,3)}')\n",
    "print(f'Test accuracy of {round(num_correct*100/len(to_eval),2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 7.8233e-01,  1.4648e-01,  4.0102e-01,  ...,  2.3998e-03,\n",
      "         -6.2271e-04, -1.0051e-01],\n",
      "        [-7.7985e-01, -1.4611e-01, -3.9964e-01,  ..., -8.9297e-04,\n",
      "         -9.6313e-04,  1.0101e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 5.4877, -5.4903], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = []\n",
    "for p in model.parameters():\n",
    "    print(p)\n",
    "    a = p.detach().numpy()\n",
    "    params.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = params[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95091,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = a.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst -49.409\n",
      "waste -33.08\n",
      "awful -31.459\n",
      "boring -29.581\n",
      "terrible -24.071\n",
      "worse -23.892\n",
      "fails -23.09\n",
      "mess -22.583\n",
      "dull -22.37\n",
      "unfortunately -22.146\n"
     ]
    }
   ],
   "source": [
    "for idx in sorted_idx[:10]:\n",
    "    print(idx_to_word[idx],round(a[idx],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brilliant 17.592\n",
      "710 18.039\n",
      "beautiful 18.873\n",
      "wonderful 20.09\n",
      "definitely 20.4\n",
      "today 20.702\n",
      "loved 21.29\n",
      "amazing 23.117\n",
      "perfect 31.693\n",
      "excellent 33.634\n"
     ]
    }
   ],
   "source": [
    "for idx in sorted_idx[-10:]:\n",
    "    print(idx_to_word[idx],round(a[idx],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [(sentence,label) for sentence,label in train_data if '710' in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_text(example):\n",
    "    sentence,label = example\n",
    "    print(f'label is {label}'.upper())\n",
    "    print('----------------------------------------')\n",
    "    print(''.join(f'{w} ' for w in sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL IS 1\n",
      "----------------------------------------\n",
      "was'nt really bad for raw 's first ppv of 006 . but the ending was really really shocking to everyone in attendance & the ones who were watching at home.  br    br   first match- ric flair vs . edge w lita for the wwe intercontinental championship not a bad opener , these two can seriously put on a great match if they had more time to put on a wrestling match . flair wins by dq after edge slams him with his mitb briefcase . 310 second match- trish stratus vs. mickie james for the wwe women 's championship not bad noticing the fact that this is the first time these divas faced off in the ring together . mickie goes for a modified chick kick , but trish ducks & nails her own chick kick for the win to retain her title . 310 third match- triple h vs. big show seriously good this match was , really . the whole match hhh focuses on big show 's injured arm but big show still fights back . later hhh is able to topple down big show & nails a pedigree for the win . 510 fourth match- shelton benjamin w mama vs. viscera { this was a bonus match } not that bad , it was alright . after viscera was down , behind the referee , benjamin 's mama got a purse { which had bricks in it } & slammed viscera on the head with it three times . viscera got up only to get caught with a spinning heel kick by benjamin for the win against the big man . 410  br    br   fifth match- jerry 'the king ' lawler vs. gregory helms boring , slow & sloppy . both men did n't really put a very good effort . jerry lawler wins after a fist drop for the win . 210  br    br   sixth match- torrie wilson vs. victoria vs. ashley vs. maria vs. candice michelle in a first ever women 's gauntlet match it was pretty entertaining to me . ashley { i think } eliminates candice last to win the first ever women 's gauntlet match . 510 seventh match- john cena vs. chris masters vs. carlito vs. shawn michaels vs. kane vs. kurt angle w daivari in an elimination chamber match for the wwe championship it was a cool elimination chamber match . but nothing will top last year 's elimination chamber which was the best . the last three are masters , cena & carlito . carlito turns his back on masters & gets a roll-up on him to eliminate him . seconds later cena gets a roll-up on carlito for the three count to win the elimination chamber & retain his wwe title . but his night was not over yet . 710 after the match , vince mcmahon comes out & congratulates cena for his victory . vince mcmahon states that his night is not over yet , & says that edge cashes in his money in the bank opportunity to challenge cena for the title . edge comes out with lita , gives the briefcase to vince & heads off in the ring as cena has one more match to go here tonight.  br    br   eight match- john cena vs . edge w lita for the wwe championship { cena who is busted open during the chamber match } gets pounded straight away by edge , edge then nails a spear on cena , goes for the cover & to his shock cena breaks out . edge nails another spear & covers for the shocking three count as he has beat cena & has won the wwe championship for the first time in his career . 110 so last year 's new years revolution was better than this year 's , but it was still alright . the ec match was also good & the shocking of edge cashing in his mitb opportunity is definitely the most shockingest on the ppv show.  br    br   overall : i 'll give it 710 & a c \n"
     ]
    }
   ],
   "source": [
    "show_text(examples[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([label for _,label in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
